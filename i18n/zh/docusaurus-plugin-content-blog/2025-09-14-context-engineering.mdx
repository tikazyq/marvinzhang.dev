---
slug: context-engineering
title: "上下文工程：从提示词制作到智能信息架构"
authors:
  - marvin
tags:
  - ai
  - llm
  - architecture
  - systems-design
  - prompt-engineering
date: '2025-09-14'
---

"上下文工程是将恰当的信息填入上下文窗口的精妙艺术与科学。" — Andrej Karpathy

如果你是一名开发者，你可能已经发现简单的prompt engineering已经不够用了。你精心设计的提示词在面对复杂任务时显得力不从心，你的AI助手在处理大量信息时变得混乱不堪，你构建的应用程序在扩展性和可靠性方面遇到了瓶颈。这些挫折感并非偶然，它们揭示了一个更深层的问题：我们正站在AI系统发展的一个重要转折点上。

在今天的AI开发领域，一场无声的革命正在发生。全球科技巨头们正在投入数十亿美元，不是为了训练更大的模型，而是为了构建更智能的信息系统。Microsoft、Google、OpenAI等公司都在重新思考如何设计AI交互的基础架构。这个转变的核心不是模型本身，而是我们如何向模型提供信息——这就是Context Engineering（上下文工程）的本质。

{/* truncate */}

传统的prompt engineering将AI交互视为一个简单的输入输出过程：你写一个提示，模型返回一个答案。但现实世界的AI应用远比这复杂。想象一下一个AI编程助手，它需要理解你的项目结构、代码历史、当前任务上下文、相关文档、以及你的编程习惯。简单的提示词无法承载如此丰富的信息。你需要的是一个智能的信息架构，能够动态地组织、筛选、和提供最相关的上下文。

Context Engineering正是解决这一挑战的系统性方法。它不再把上下文视为静态的文本字符串，而是将其重新定义为"动态的、结构化的组件集合"。这些组件通过明确的函数来源、选择、过滤、排序和组织，在有限的上下文窗口、延迟预算和计算成本的约束下运行。这种转变标志着我们从"模型中心"向"系统中心"的AI开发范式迁移。

## 超越提示词：上下文的架构

当我们深入理解Context Engineering时，首先需要认识到传统prompt engineering方法的根本局限性。想象一下你正在构建一个AI驱动的代码审查助手。使用传统的prompt engineering方法，你可能会写这样的提示：

```typescript
// 传统prompt engineering方法的局限性
const simplePrompt = `
请审查以下代码并提供改进建议：
[代码片段]
`;

// 这种方法忽略了：
// - 项目架构和上下文
// - 代码标准和最佳实践
// - 相关测试和文档
// - 历史修改记录
```

传统prompt engineering的核心问题在于它将上下文视为一个单一的、静态的文本块。这种方法存在三个根本性限制：

**1. 上下文窗口约束**：即使是最先进的模型，其上下文窗口也是有限的。当你需要提供大量背景信息时，你很快就会撞到这个硬性限制。

**2. 静态信息问题**：Prompt engineering假设所有必要的信息都可以在请求时预先确定并包含在提示中。但实际上，最相关的信息往往是动态的，需要根据任务的具体情况实时检索和组织。

**3. 缺乏反馈机制**：传统方法是一次性的输入输出过程，无法根据中间结果调整上下文策略。

### 信息论视角

从信息论的角度重新思考这个问题，我们可以将上下文窗口视为一个有限带宽的通信信道。Claude Shannon的信息理论告诉我们，在这样的信道中，我们的目标应该是最大化有效信息的传输，同时最小化噪声。

```typescript
// 信息论驱动的上下文优化示例
class ContextOptimizer {
  calculateInformationGain(content: string, existingContext: string[]): number {
    // 计算新内容相对于现有上下文的信息增益
    const entropy = this.calculateEntropy(content);
    const conditionalEntropy = this.calculateConditionalEntropy(content, existingContext);
    return entropy - conditionalEntropy;
  }

  selectOptimalContext(candidates: string[], maxTokens: number): string[] {
    // 使用贪心算法选择信息增益最大的上下文组合
    const selected: string[] = [];
    let remainingTokens = maxTokens;
    
    while (remainingTokens > 0 && candidates.length > 0) {
      const best = candidates.reduce((prev, curr) => 
        this.calculateInformationGain(curr, selected) > 
        this.calculateInformationGain(prev, selected) ? curr : prev
      );
      
      if (this.getTokenCount(best) <= remainingTokens) {
        selected.push(best);
        remainingTokens -= this.getTokenCount(best);
      }
      
      candidates = candidates.filter(c => c !== best);
    }
    
    return selected;
  }
}
```

### 系统思维方法

系统思维将Context Engineering视为设计复杂自适应系统的挑战。在这个框架中，上下文不是静态的数据，而是一个动态系统的状态，这个系统包含多个相互作用的组件：

1. **感知子系统**：负责从各种来源收集潜在相关的信息
2. **过滤子系统**：根据当前任务和历史表现筛选信息
3. **组织子系统**：将选中的信息结构化为最适合模型处理的格式
4. **反馈子系统**：监控系统性能并调整策略

```typescript
// 系统思维的上下文管理示例
class ContextSystem {
  private perceptionModule: PerceptionModule;
  private filterModule: FilterModule;
  private organizationModule: OrganizationModule;
  private feedbackModule: FeedbackModule;

  async processQuery(query: string): Promise<string> {
    let context = await this.perceptionModule.gatherCandidates(query);
    context = await this.filterModule.selectRelevant(context, query);
    const structuredContext = await this.organizationModule.structure(context);
    
    const result = await this.llm.generate(query, structuredContext);
    
    // 关键：反馈循环
    const feedback = await this.feedbackModule.evaluateResult(result, query);
    await this.adaptStrategies(feedback);
    
    return result;
  }
}
```

## 上下文组装管道

在理解了Context Engineering的架构原理之后，我们现在深入探讨其最核心的组成部分：上下文组装管道。这个管道负责从各种来源收集、筛选、组织信息，并将其转化为LLM能够有效处理的结构化上下文。

### 上下文学习的演进

在Context Engineering中，In-Context Learning（ICL）技术的演进代表了从简单数据提供到复杂推理编程的根本转变：

**Few-Shot学习 → 思维链 → 思维树 → 思维图**

这种演进的核心洞察是：上下文正在成为一种编程语言，用于指定LLM应该执行的推理算法。

```typescript
// 思维树推理结构示例
class TreeOfThoughtAnalyzer {
  async analyzeBusinessDecision(situation: string): Promise<Analysis> {
    // 生成多个初始思路方向
    const initialThoughts = await this.generateThoughts(situation, [
      "从财务角度考虑",
      "从战略角度考虑", 
      "从运营角度考虑",
      "从风险角度考虑"
    ]);

    // 评估每个思路的可行性
    const evaluatedThoughts = await Promise.all(
      initialThoughts.map(thought => this.evaluateThought(thought, situation))
    );

    // 选择最有前景的路径继续探索
    const promisingPaths = evaluatedThoughts
      .filter(thought => thought.viabilityScore > 0.7)
      .slice(0, 3);

    // 对每个有前景的路径深入分析
    const deepAnalyses = await Promise.all(
      promisingPaths.map(path => this.deepenAnalysis(path, situation))
    );

    // 综合所有分析路径的结果
    return this.synthesizeAnalyses(deepAnalyses);
  }
}
```

### 检索增强生成（RAG）

RAG技术的演进同样反映了从简单检索到智能信息整合的发展。现代RAG系统不再是简单的"搜索-检索-生成"流水线，而是复杂的信息处理系统：

```typescript
// 模块化RAG系统设计
class ModularRAGSystem {
  constructor(
    private queryTransformer: QueryTransformer,
    private retriever: VectorRetriever,
    private reranker: CrossEncoderReranker,
    private contextOrganizer: ContextOrganizer,
    private generator: LLMGenerator
  ) {}

  async processQuery(query: string, options: RAGOptions = {}): Promise<RAGResponse> {
    // 第一阶段：查询理解和扩展
    const transformedQueries = await this.queryTransformer.transform(query, {
      expandSynonyms: true,
      generateSubQueries: true,
      identifyIntent: true
    });

    // 第二阶段：多策略检索
    const retrievalResults = await Promise.all([
      this.semanticRetrieval(transformedQueries.main),
      this.keywordRetrieval(transformedQueries.keywords),
      this.structuredRetrieval(transformedQueries.entities)
    ]);

    // 第三阶段：智能重排序
    const combinedResults = this.combineResults(retrievalResults);
    const rerankedResults = await this.reranker.rerank(
      query, 
      combinedResults,
      { maxResults: options.maxResults || 10 }
    );

    // 第四阶段：上下文组织
    const organizedContext = await this.contextOrganizer.organize(
      rerankedResults,
      transformedQueries,
      { strategy: 'hierarchical', preserveProvenance: true }
    );

    // 第五阶段：增强生成
    const response = await this.generator.generate(query, organizedContext, {
      citeSources: true,
      confidenceThreshold: 0.8
    });

    return {
      answer: response.text,
      sources: organizedContext.sources,
      confidence: response.confidence,
      reasoning: response.reasoning
    };
  }
}
```

## 扩展上下文：长序列处理与内存管理

随着上下文组装管道变得越来越复杂，我们面临一个新的挑战：如何处理和管理大规模的上下文？传统的Transformer架构在处理长序列时面临二次复杂度的瓶颈，而现实世界的应用往往需要处理数十万甚至数百万token的上下文。

### 突破二次复杂度限制

标准Transformer的注意力机制的计算复杂度是O(n²)，这意味着当序列长度翻倍时，计算成本会增加四倍。让我们看看几种突破这一限制的架构创新：

**FlashAttention：算法优化的力量**

```typescript
// FlashAttention的核心思想：分块计算
class FlashAttentionImpl {
  // 传统注意力：O(n²)内存，需要存储完整的注意力矩阵
  traditionalAttention(Q: Matrix, K: Matrix, V: Matrix): Matrix {
    const scores = matmul(Q, K.transpose()); // n x n 矩阵
    const weights = softmax(scores); // 存储完整注意力矩阵
    return matmul(weights, V);
  }

  // FlashAttention：O(n)内存，分块计算避免存储完整矩阵
  flashAttention(Q: Matrix, K: Matrix, V: Matrix, blockSize: number): Matrix {
    const [seqLen, dimHead] = Q.shape;
    const numBlocks = Math.ceil(seqLen / blockSize);
    let output = zeros([seqLen, dimHead]);
    let maxScores = fill(-Infinity, [seqLen]);
    let sumExp = zeros([seqLen]);

    // 按块处理，避免存储完整注意力矩阵
    for (let i = 0; i < numBlocks; i++) {
      for (let j = 0; j < numBlocks; j++) {
        const qBlock = Q.slice(i * blockSize, (i + 1) * blockSize);
        const kBlock = K.slice(j * blockSize, (j + 1) * blockSize);
        const vBlock = V.slice(j * blockSize, (j + 1) * blockSize);
        
        // 计算局部注意力分数
        const localScores = matmul(qBlock, kBlock.transpose());
        
        // 在线更新注意力权重和输出
        this.updateOnline(output, maxScores, sumExp, localScores, vBlock, i, j);
      }
    }

    return output;
  }
}
```

**Mamba：状态空间模型的革命**

Mamba代表了一种根本不同的方法，基于状态空间模型而非注意力机制：

```typescript
// Mamba/SSM的核心概念
class MambaLayer {
  private stateSize: number;
  private hiddenSize: number;
  
  // Mamba的关键创新：选择性状态空间模型
  forward(input: Tensor, state: State): { output: Tensor, newState: State } {
    // 1. 输入依赖的参数生成（选择机制）
    const params = this.generateInputDependentParams(input);
    
    // 2. 状态更新（线性复杂度）
    const newState = this.updateState(state, input, params);
    
    // 3. 输出生成
    const output = this.generateOutput(newState, params);
    
    return { output, newState };
  }

  // 这使得Mamba能够处理理论上无限长的序列
  processInfiniteStream(tokenStream: AsyncIterable<Tensor>): AsyncIterable<Tensor> {
    return this.transformStream(tokenStream, token => this.processToken(token));
  }
}
```

### 内存层次结构

仅仅能够处理长序列是不够的，我们还需要构建能够持久保存和智能检索信息的内存系统。这需要设计类似计算机内存层次结构的多级存储架构：

```typescript
// 分层内存架构
class HierarchicalMemorySystem {
  private l1Cache: ActiveContextWindow;    // 快速访问，有限容量
  private l2Cache: VirtualContextManager;  // 中等访问，扩展容量
  private l3Storage: PersistentVectorStore; // 慢速访问，大容量

  async processWithMemory(query: string, sessionId: string): Promise<Response> {
    // L1: 检查活跃上下文窗口
    let context = await this.l1Cache.getRelevantContext(query);
    
    if (!this.isContextSufficient(context, query)) {
      // L2: 从虚拟上下文中分页加载
      const pagedContext = await this.l2Cache.pageIn(query, sessionId);
      context = this.mergeContexts(context, pagedContext);
      
      if (!this.isContextSufficient(context, query)) {
        // L3: 从长期存储中检索
        const longTermMemories = await this.l3Storage.retrieve(query, sessionId);
        context = this.mergeContexts(context, longTermMemories);
      }
    }
    
    // 生成响应
    const response = await this.llm.generate(query, context);
    
    // 更新内存层次结构
    await this.updateMemoryHierarchy(query, response, sessionId);
    
    return response;
  }
}
```

## 多智能体上下文协调

当我们将Context Engineering扩展到多智能体系统时，我们面临一个全新的挑战维度：如何让多个AI智能体有效地共享上下文，协调行动，并产生超越单个智能体能力的集体智能。

### 多智能体系统的架构模式

**层次化架构：指挥-执行模式**

```typescript
// 层次化多智能体系统
class OrchestratorAgent {
  private workers: Map<string, WorkerAgent>;
  private sharedContext: SharedContextStore;
  private taskQueue: TaskQueue;

  async executeComplexProject(project: ProjectSpec): Promise<ProjectResult> {
    // 1. 项目分析和任务分解
    const analysisContext = await this.analyzeProject(project);
    await this.sharedContext.update('project-analysis', analysisContext);

    const tasks = await this.decomposeProject(project, analysisContext);
    
    // 2. 能力匹配和任务分配
    const assignments = this.assignTasksToWorkers(tasks);
    
    // 3. 并行执行和协调
    const executionPromises = assignments.map(async (assignment) => {
      return this.coordinateExecution(assignment);
    });

    const results = await Promise.all(executionPromises);
    
    // 4. 结果整合和质量保证
    return this.integrateResults(results, project);
  }
}
```

**对等协作架构：黑板模式**

在对等架构中，智能体通过共享工作空间（黑板）进行协作：

```typescript
// 黑板协作系统
class BlackboardCollaborationSystem {
  private blackboard: SharedBlackboard;
  private agents: Set<CollaborativeAgent>;
  private coordinationRules: CoordinationRuleEngine;

  async solveCollaborativeProblem(problem: ComplexProblem): Promise<Solution> {
    // 初始化黑板
    await this.blackboard.initialize(problem);
    
    // 启动所有智能体
    const agentPromises = Array.from(this.agents).map(agent => 
      this.runAgentLoop(agent)
    );
    
    // 等待解决方案收敛
    const solution = await this.waitForConvergence();
    
    return solution;
  }
}
```

### 上下文同步策略

在多智能体系统中，上下文同步是一个核心挑战。我们需要确保所有智能体都有一致且最新的上下文视图，同时避免通信开销过大：

```typescript
// 上下文同步管理器
class ContextSynchronizationManager {
  private agents: Map<string, AgentNode>;
  private versionVector: VersionVector;
  private updateLog: UpdateLog;

  async syncContext(
    sourceAgent: string, 
    update: ContextUpdate,
    syncScope: SyncScope = 'relevant'
  ): Promise<SyncResult> {
    
    // 1. 确定同步范围
    const targetAgents = this.determineSyncTargets(update, syncScope);
    
    // 2. 检查版本冲突
    const conflicts = this.detectVersionConflicts(update, targetAgents);
    
    if (conflicts.length > 0) {
      // 解决冲突
      const resolved = await this.resolveConflicts(conflicts, update);
      update = resolved;
    }
    
    // 3. 执行增量同步
    const syncResults = await Promise.all(
      targetAgents.map(agent => this.syncWithAgent(agent, update))
    );
    
    return this.aggregateSyncResults(syncResults);
  }
}
```

## 评估、优化与前进之路

随着Context Engineering系统变得越来越复杂，我们面临一个关键挑战：如何评估这些系统的性能？如何优化它们的效率？传统的评估指标在面对多步推理、动态检索和多智能体协作时显得力不从心。

### 超越BLEU：面向过程的评估

传统的NLP评估指标如BLEU、ROUGE主要关注最终输出与参考答案的相似性，但Context Engineering系统的价值在于其处理过程的质量。我们需要从"结果导向"转向"过程导向"的评估：

```typescript
// 全面的上下文工程评估框架
class ContextEngineeringEvaluator {
  async evaluateSystem(
    system: ContextEngineeredSystem,
    evaluationConfig: EvaluationConfig
  ): Promise<ComprehensiveEvaluation> {
    
    const evaluation = new ComprehensiveEvaluation();
    
    // 1. 上下文组装质量评估
    const assemblyMetrics = await this.evaluateContextAssembly(
      system.assemblyPipeline,
      evaluationConfig.assemblyTests
    );
    evaluation.addSection('context-assembly', assemblyMetrics);

    // 2. 检索系统评估
    const retrievalMetrics = await this.evaluateRetrievalQuality(
      system.retrievalComponents,
      evaluationConfig.retrievalBenchmarks
    );
    evaluation.addSection('retrieval-quality', retrievalMetrics);

    // 3. 推理过程评估
    const reasoningMetrics = await this.evaluateReasoningProcess(
      system.reasoningEngine,
      evaluationConfig.reasoningTasks
    );
    evaluation.addSection('reasoning-process', reasoningMetrics);

    // 4. 安全性和鲁棒性评估
    const safetyMetrics = await this.evaluateSafety(
      system,
      evaluationConfig.safetyTests
    );
    evaluation.addSection('safety-robustness', safetyMetrics);

    return evaluation;
  }
}
```

### 上下文优化策略

优化Context Engineering系统需要在质量、成本和延迟之间找到平衡：

```typescript
// 多层次优化框架
class ContextOptimizationFramework {
  private costModel: CostModel;
  private qualityModel: QualityModel;
  private latencyModel: LatencyModel;

  async optimizeSystem(
    system: ContextEngineeredSystem,
    objectives: OptimizationObjectives
  ): Promise<OptimizationResult> {
    
    // 1. 成本效益分析
    const costBenefit = await this.analyzeCostBenefit(system);
    
    // 2. 动态上下文分配优化
    const contextAllocation = await this.optimizeContextAllocation(
      system,
      objectives.qualityThreshold
    );
    
    // 3. 检索策略优化
    const retrievalOptimization = await this.optimizeRetrievalStrategy(
      system.retrievalComponents,
      objectives.latencyBudget
    );
    
    return this.combineOptimizations([
      contextAllocation,
      retrievalOptimization
    ]);
  }
}
```

## 总结：从提示词到智能系统的演进

在这篇文章中，我们见证了一个深刻的范式转变：从简单的prompt engineering到复杂的Context Engineering。这不仅仅是技术的进步，更代表了AI开发思维的根本性转变。

### 三个核心洞察

1. **系统即AI**：在Context Engineering时代，真正的智能不在于模型本身，而在于围绕模型构建的整个信息系统。LLM正在成为通用的推理引擎，而差异化竞争将集中在上下文管理能力上。

2. **信息即架构**：Context Engineering本质上是信息架构的设计问题。我们需要运用信息论、系统工程和软件架构的原理，来设计高效的信息流动和处理机制。

3. **智能即涌现**：最令人兴奋的AI能力往往不是单个组件的功能，而是整个系统协调运作时的涌现现象。精心设计的上下文协调机制能够催生超越各部分能力总和的集体智能。

### 给开发者的行动建议

作为软件开发者，如何在这个变革时代中保持竞争力？

**立即开始**：
- 从构建简单的RAG系统开始，理解检索-增强-生成的基本原理
- 实验不同的上下文组织策略，如思维链和思维树
- 建立对向量数据库和嵌入技术的深入理解

**建立系统思维**：
- 学习信息论和系统工程的基础概念
- 掌握分布式系统和数据流架构的设计原理
- 培养从整体视角思考AI应用架构的能力

**关注前沿发展**：
- 跟踪长序列模型和记忆增强架构的最新进展
- 研究多智能体系统的协调机制和实现模式
- 参与开源社区，贡献和学习Context Engineering的最佳实践

### 结语：迎接智能系统的新时代

Context Engineering不仅仅是一套技术方法，更代表了AI发展的新阶段。在这个阶段，我们不再满足于训练更大的模型，而是专注于构建更智能的系统。我们不再仅仅关注算法的优化，而是追求信息架构的完美。

作为一名软件工程师，你现在正站在一个历史性的转折点上。传统的软件开发技能仍然重要，但Context Engineering的系统性思维将成为你在AI时代的核心竞争力。掌握这些技能，你就能够设计和构建真正智能的应用，让AI系统不仅仅能够回答问题，更能够理解复杂的情境，处理大规模的信息，并与人类和其他AI进行有效的协作。

未来已来，让我们一起拥抱Context Engineering的无限可能，共同构建更智能、更有用、更安全的AI系统。在这个激动人心的旅程中，每一行代码、每一个架构决策、每一次优化，都可能成为推动人工智能发展的重要贡献。

作为软件工程师，你需要不断学习，持续实践，并与社区分享你的经验和洞察。Context Engineering的未来需要我们每一个人的参与和贡献。

## 特别鸣谢

感谢 Google Gemini 和 xAI Grok 在本文创作过程中提供的强力支持！

## 社区

如果你对我的文章感兴趣，可以添加我的微信 tikazyq1 备注「码之道」，我会邀请你加入「码之道」讨论群。

## 主要引用

1. A Technical Roadmap to Context Engineering in LLMs - Deep Research Reports, 访问日期：2025年1月15日
2. Context Engineering GitHub Resources - Carlisia Campos, 访问日期：2025年1月15日
3. LangChain Blog on Context Engineering for Agents - 访问日期：2025年1月15日
4. Context-Space Organization Building Infrastructure - 访问日期：2025年1月15日